# Політики керування чергами та backpressure

Цей документ узгоджує підхід TradePulse до керування потоками подій та навантаженням у сервісах, що працюють з маркет-дейтами, торговими сигналами та оркестрацією стратегій. Правила орієнтовані на стабільність трафіку, запобігання перевантаженням і контроль деградації під час пікових навантажень.

## Цілі

- **Стабільність трафіку.** Стримувати короткочасні сплески, щоб критичні сервіси (ingestion, оркестрація стратегій, risk guards) залишалися доступними.
- **Врегулювання швидкості потоків.** Координувати продюсерів і конс'юмерів так, щоби середнє навантаження відповідало пропускній здатності найповільнішого вузла.
- **Контроль обсягу подій.** Обмежувати кількість задач/заявок у чергах, запобігаючи витісненню пріоритетних елементів та неконтрольованому росту пам'яті.
- **Деградація без відмови.** Забезпечити прогнозовані режими деградації (drop/skip/сampeling), коли система не може обробляти всі події.

## Архітектурні принципи

1. **Визначені межі**. Для кожної черги встановлюються `high_water_mark`, `low_water_mark` та політика очищення. Наприклад, `StrategyOrchestrator` (див. `core/agent/orchestrator.py`) використовує `PriorityQueue` з параметром `max_queue_size`, що визначає ліміти на чергу виконання стратегій.
2. **Окремі плейни трафіку**. Інгест, backtest, live execution та алерти працюють у власних чергах/каналах (через Kafka, Redis Streams або in-memory черги), що дозволяє незалежно застосовувати throttling.
3. **Пріоритезація**. Черги мають підтримувати пріоритети (наприклад, SEV-операції або ризикові події мають нижче числове значення пріоритету) та політику витіснення низького пріоритету, коли high-water спрацьовує.
4. **Ідемпотентність**. Усі конс'юмери зобов'язані бути ідемпотентними: повторна доставка або requeue не повинні призводити до додаткових побічних ефектів.

## Політики backpressure

| Сценарій | Опис | Тактики | Пороги |
| --- | --- | --- | --- |
| **Продюсер перевищує пропускну здатність** | Наприклад, біржа надсилає значно більше тикових подій, ніж може обробити pipeline. | 1) `credit-based` протокол між сервісами; 2) динамічне зниження частоти публікації (adaptive rate limiting). | High-water 80% → приглушення, 95% → пауза продюсера.
| **Повільний конс'юмер** | Наприклад, повільні адаптери брокера або аналітичні обчислення. | 1) back-pressure сигнал у вигляді HTTP 429/`Retry-After`; 2) перерозподіл роботи (`max_parallel` зменшити) + масштабування воркерів. | 3 послідовні тайм-аути → вимкнути воркер та переспрямувати в резервні.
| **Сплеск пріоритетних подій** | Ринкові алерти, які мають виконатися раніше backtest задач. | 1) тимчасовий drop або sampling низьких пріоритетів; 2) розширення headroom за рахунок резервних воркерів. | 60% від headroom → сигнал SRE, 80% → превентивне розширення пулу.
| **Деградація інфраструктури** | Зменшення пропускної здатності бази, збої мережі. | 1) входити в режим read-only; 2) збільшити `ack` тайм-аути; 3) включити буферизацію на диску/об'єктному сховищі. | Виявлення 5 хвилинної деградації → запуск runbook `runbook_time_synchronization.md`/`runbook_live_trading.md` залежно від сегменту.

## Обмеження черг та sizing

1. **Розрахунок лімітів**: `max_queue_size = peak_rate * failover_window`. Для ingestion це `ticks_per_sec * 120s`; для оркестрації стратегій `strategies_per_min * 2min`.
2. **High-water сигналізація**: метрики `queue_depth_ratio`, `oldest_message_age`, `enqueue_rate` → поріг 0.75 тригерить попередження; 0.9 → аварійний канал.
3. **Dead-letter політика**: елементи, які не оброблені за `max_retry_window`, переміщуються в dead-letter чергу з атрибутами `last_error`, `attempts`, `payload_digest`.
4. **Зв'язок з rate limit**: глобальні rate-limiters (`leaky bucket` або `token bucket`) повинні синхронізуватись з фактичним станом черги. Якщо `available_tokens > queue_headroom`, виділяється лише `headroom`.

## Інструменти моніторингу та телеметрія

- **Метрики**: `queue_depth`, `queue_latency_p95`, `dropped_events_total`, `backpressure_active{source=...}` публікуються в Prometheus. Для `StrategyOrchestrator` експортуємо `active_workers`, `pending_flows` та кількість відхилених submit-ів (TimeoutError).
- **Логи**: при вході в режим backpressure логуються структуровані повідомлення з полями `queue`, `threshold`, `action`, `expected_duration`.
- **Трейсинг**: додаємо `span` атрибут `flow_control.state` = `normal|throttled|paused`, щоб простежити вплив на end-to-end латентність.
- **Дашборди**: у Grafana створюємо панелі "Queue Saturation", "Backpressure Reasons", "Dropped payloads" із розбиттям по доменах (ingestion, execution, analytics).

## Операційні процедури

1. **Runbook реагування**
   - 70% заповнення → SRE перевіряє останні релізи/зміни у продюсерах.
   - 85% → включити деградований режим (sampling, збільшення batch розміру, вимкнення нефункціональних воркерів).
   - 95% → зупинка нових продюсерів, фокус на вивільнення черги, оголошення SEV-2 інциденту.
2. **Тестування**: для нових сервісів проводимо `load spike test` (x3 від середнього), `sustained soak` (1 година) і `failover simulation` (штучне зниження пропускної здатності).
3. **Change management**: будь-яка зміна параметрів `max_parallel`, `max_queue_size`, `rate_limit` проходить через change request із валідацією capacity-моделі.

## Рекомендації для розробників

- Використовуйте неблокуючі алгоритми (наприклад, `asyncio.Queue` або неблокуючі продюсери Kafka) з тайм-аутами і явними сигналами для backpressure.
- Інкапсулюйте політику в окремі модулі/класі (наприклад, `FlowController`, `QueueLimiter`), щоб легко змінювати стратегії throttling.
- Документуйте очікувану швидкість і розмір payload у README сервісу; ці значення стають базовими під час capacity review.
- Підтримуйте автоматичні тести, що перевіряють поведінку при `Full`/`Empty` винятках (аналогічно тесту `test_orchestrator_applies_backpressure`).

## Checklist перед релізом

1. Метрики backpressure підключені до дашбордів і мають пороги alerting.
2. Конфігурація черг описана в інфраструктурному коді (`infra/` або Helm chart) та проходить review.
3. Runbook із деградації оновлено і прив'язано до PagerDuty сценаріїв.
4. Сервіс має інтеграційний тест із навантаженням, який підтверджує коректне спрацьовування backpressure.

Дотримання цих практик забезпечує передбачуване масштабування TradePulse, дозволяючи системі витримувати пікові торгові сесії без втрати даних або порушення SLA.
